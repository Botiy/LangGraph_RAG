{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69dc94a2-fab4-4056-85bd-21573942f695",
   "metadata": {},
   "source": [
    "# Chatbot application using RAG - made by Horváth Botond\n",
    "> The goal of this notebook is to present a chatbot application, which is based on Retrieval Augmented Generation.\n",
    "\n",
    "Expectations:\n",
    "* The chatbot should demonstrate the basic elements of agentic behavior,\n",
    "autonomous decision making, autonomous decomposition of subtasks and\n",
    "execution.\n",
    "* The application must use the Retrieval-Augmented Generation (RAG)\n",
    "technique to integrate external knowledge sources.\n",
    "* The solution should include structured documentation of the design\n",
    "design decisions, architecture used and operational logic.\n",
    "\n",
    "## Steps\n",
    "1. Setting up the environment\n",
    "2. Loading and saving the data\n",
    "3. Splitting text into chunks\n",
    "4. Creating embeddings and building vector database\n",
    "5. Define tools and agent\n",
    "6. Testing nodes and RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2289f4b3-af84-4e8b-b993-cfbdab83404c",
   "metadata": {},
   "source": [
    "### 1. Setting up the environment\n",
    "* Hugging Face -> models and datasets\n",
    "* LangChain -> chaining and retrieval \n",
    "* FAISS -> vector store\n",
    "* LangGraph -> agentic logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e46b4ba6-5043-49da-baa5-f60268b05772",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Installing required packages\n",
    "%pip install -q langchain-community langgraph faiss-cpu huggingface_hub transformers sentence-transformers datasets tiktoken unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7673e9a0-aace-4b8d-b863-2167d22c859c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mwparserfromhell in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.6.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Installing parser\n",
    "%pip install mwparserfromhell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b50c0de2-6264-4a80-a855-c595390a1787",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate>=0.26.0) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate>=0.26.0) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate>=0.26.0) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate>=0.26.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate>=0.26.0) (2.7.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate>=0.26.0) (0.31.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate>=0.26.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2025.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate>=0.26.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install \"accelerate>=0.26.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c316e48-625d-4700-9df2-e4b02965e452",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.45.5)\n",
      "Requirement already satisfied: torch<3,>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bitsandbytes) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bitsandbytes) (1.26.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05fc20ed-8b5d-416f-b199-1063187a4f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "\n",
    "# Core libraries\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from typing import List\n",
    "\n",
    "# Hugging Face & Transformers\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "\n",
    "# LangChain for RAG logic\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain import LLMChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "# LangGraph for agentic execution\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Utilities\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c53e32-23c5-4191-bb4f-21e3ee612665",
   "metadata": {},
   "source": [
    "### 2. Loading and saving the data\n",
    "> Loading a legacy dataset from HuggingFace.\n",
    "\n",
    "> Saving 500 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c302efc8-ee8a-4665-9f88-e90c1cfedbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in streaming mode, because it takes up less disc space\n",
    "streamed_dataset = load_dataset(\"wikipedia\", \"20220301.en\", split=\"train\", streaming=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86d2661b-9b76-4552-a847-d9e80151dfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 500 articles.\n"
     ]
    }
   ],
   "source": [
    "# Getting a sample from the data\n",
    "sampled_data = []\n",
    "for i, article in enumerate(streamed_dataset):\n",
    "    if i >= 500:\n",
    "        break\n",
    "    sampled_data.append(article)\n",
    "\n",
    "print(f\"Collected {len(sampled_data)} articles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d32e5d3c-c649-46d3-a31f-70f3f986e176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Anarchism\n",
      "2. Autism\n",
      "3. Albedo\n",
      "4. A\n",
      "5. Alabama\n",
      "6. Achilles\n",
      "7. Abraham Lincoln\n",
      "8. Aristotle\n",
      "9. An American in Paris\n",
      "10. Academy Award for Best Production Design\n"
     ]
    }
   ],
   "source": [
    "# Print titles of the first 10 articles\n",
    "for i, article in enumerate(sampled_data[:10]):\n",
    "    print(f\"{i+1}. {article['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9051baf-b30a-475c-9dc5-5798fba342e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Academy Award for Best Production Design\n",
      "URL: https://en.wikipedia.org/wiki/Academy%20Award%20for%20Best%20Production%20Design\n",
      "\n",
      "The Academy Award for Best Production Design recognizes achievement for art direction in film. The category's original name was Best Art Direction, but was changed to its current name in 2012 for the 85th Academy Awards. This change resulted from the Art Director's branch of the Academy of Motion Pi\n"
     ]
    }
   ],
   "source": [
    "# Viewing one article\n",
    "sample_article = sampled_data[0]\n",
    "\n",
    "print(f\"Title: {article['title']}\")\n",
    "print(f\"URL: {article['url']}\\n\")\n",
    "print(article['text'][:300])  # Show only the first 300 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af0aa49e-7665-4ad0-be0c-df420e704fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 500 articles to 'data'\n"
     ]
    }
   ],
   "source": [
    "# Saving articles\n",
    "\n",
    "# Creating a directory\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Save each article\n",
    "for i, article in enumerate(sampled_data):\n",
    "    filename = f\"{article['title']}.json\"\n",
    "    filepath = os.path.join(\"data\", filename)\n",
    "    \n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(article, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved {len(sampled_data)} articles to 'data'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a5b38d-0783-4fe3-8bc3-b4c7f0d7b7e8",
   "metadata": {},
   "source": [
    "### 3. Splitting text into chunks\n",
    "> Converting articles to LangChain documents\n",
    "\n",
    "> Specifying chunk size and overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "face5b2e-e177-4748-a5bf-51b9792f64e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of text chunks: 46103\n",
      "\n",
      "Sample chunk (from article: Anarchism):\n",
      "\n",
      "Anarchism is a political philosophy and movement that is sceptical of authority and rejects all involuntary, coercive forms of hierarchy. Anarchism calls for the abolition of the state, which it holds to be unnecessary, undesirable, and harmful. As a historically left-wing movement, placed on the farthest left of the political spectrum, it is usually described alongside communalism and libertarian\n"
     ]
    }
   ],
   "source": [
    "# LangChain Document objects\n",
    "documents = [Document(page_content=article[\"text\"], metadata={\"title\": article[\"title\"]}) for article in sampled_data]\n",
    "\n",
    "# Use recursive character splitter\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,      # Characters per chunk\n",
    "    chunk_overlap=50     # Overlap between chunks to preserve context\n",
    ")\n",
    "\n",
    "# Split the documents into chunks\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Total number of text chunks: {len(chunks)}\")\n",
    "print(f\"\\nSample chunk (from article: {chunks[0].metadata['title']}):\\n\")\n",
    "print(chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0929c52c-174e-4a9e-9c4f-ec70cff169a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average chunks per article: 92.21\n"
     ]
    }
   ],
   "source": [
    "# Average chunk number in one article\n",
    "print(f\"Average chunks per article: {len(chunks) / len(sampled_data):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051df625-8003-498a-a93e-e15468c5dc69",
   "metadata": {},
   "source": [
    "### 4. Creating embeddings and building vector database\n",
    "> Choosing an embedding model\n",
    "\n",
    "> Build vector database with FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f2707c2-5dfd-4fee-8f38-ccbadc7e1e42",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7836\\2206038898.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "# Load a sentence transformer model\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "652487ae-3659-48b6-ab75-37e3614d281f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faiss.loader:Loading faiss with AVX512 support.\n",
      "INFO:faiss.loader:Could not load library with AVX512 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx512'\")\n",
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Successfully loaded faiss with AVX2 support.\n",
      "INFO:faiss:Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing FAISS vector store...\n"
     ]
    }
   ],
   "source": [
    "VECTORSTORE_PATH = \"vectorstore/faiss_index\"\n",
    "\n",
    "if os.path.exists(VECTORSTORE_PATH):\n",
    "    print(\"Loading existing FAISS vector store...\")\n",
    "    vectorstore = FAISS.load_local(VECTORSTORE_PATH, \n",
    "                                   embeddings=embedding_model,\n",
    "                                   allow_dangerous_deserialization=True)\n",
    "else:\n",
    "    print(\"Building FAISS vector store from chunks...\")\n",
    "    vectorstore = FAISS.from_documents(chunks, embedding_model)\n",
    "    vectorstore.save_local(VECTORSTORE_PATH)\n",
    "    print(\"FAISS vector store created and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f64c985-fccd-465d-b6f5-afdee5e5fed9",
   "metadata": {},
   "source": [
    "### 5. Define tools and agent\n",
    "> Define search tool\n",
    "\n",
    "> Define agent with tool\n",
    "\n",
    "> Define nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "080eb118-8b3f-4895-8042-ac9bc9cbf6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining tool for searching\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"vectorstore_search\",\n",
    "    description=\"Searches the document store for relevant context.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbf73862-408c-4318-9070-7ba69efa077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function for loading generator model\n",
    "def load_local_model(model_id):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id)  # no quantization\n",
    "    pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512)\n",
    "    return HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d88bacdd-635d-4834-83eb-ddc5b0bdadfa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: accelerate\n",
      "Version: 1.7.0\n",
      "Summary: Accelerate\n",
      "Home-page: https://github.com/huggingface/accelerate\n",
      "Author: The HuggingFace team\n",
      "Author-email: zach.mueller@huggingface.co\n",
      "License: Apache\n",
      "Location: C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\n",
      "Requires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac8aceed-4d2b-4038-9a3d-a34b7bfc34ed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c13df8adbd748ddb6452bb0d1319b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/115 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7836\\1393137981.py:6: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  return HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "# Loading generator model\n",
    "model_id = \"tiiuae/falcon-rw-1b\"\n",
    "llm = load_local_model(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d9a1f34-98f5-4f8b-bd7d-42230a418169",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f86383d-c76d-4743-9b1d-263731f34abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent with tool\n",
    "\n",
    "from typing import TypedDict\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "import re\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    output: str\n",
    "    docs: list  # store documents from retriever\n",
    "    used_rag: bool\n",
    "\n",
    "def retrieval_node(state: AgentState) -> AgentState:\n",
    "    print(\"[Node] retrieval_node\")\n",
    "    query = state[\"input\"]\n",
    "    docs = retriever_tool.invoke(query)\n",
    "    return {\n",
    "        **state,\n",
    "        \"docs\": docs,\n",
    "        \"used_rag\": bool(docs) and len(docs) > 1\n",
    "    }\n",
    "\n",
    "def rag_generation_node(state: AgentState) -> AgentState:\n",
    "    print(\"[Node] rag_generation_node\")\n",
    "    query = state[\"input\"]\n",
    "    docs = state[\"docs\"]\n",
    "    context = \"\\n\\n\".join(\n",
    "        [doc.page_content if hasattr(doc, \"page_content\") else str(doc) for doc in docs]\n",
    "    )\n",
    "    prompt = f\"Use the following context to answer:\\n\\n{context}\\n\"\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    # Normalize response\n",
    "    if isinstance(response, list):\n",
    "        response = \"\".join(response)\n",
    "    elif hasattr(response, \"content\"):\n",
    "        response = response.content\n",
    "    elif isinstance(response, bytes):\n",
    "        response = response.decode(\"utf-8\")\n",
    "\n",
    "    response = response.replace(\"\\n\", \"\").strip()\n",
    "    response = re.sub(r\"[^\\x20-\\x7E]+\", \"\", response)   # Remove non-ASCII\n",
    "\n",
    "    return {**state, \"output\": response}\n",
    "\n",
    "\n",
    "def fallback_generation_node(state: AgentState) -> AgentState:\n",
    "    print(\"[Node] fallback_generation_node\")\n",
    "    query = state[\"input\"]\n",
    "    prompt = f\"Answer the following question as best as you can:\\n\"\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    # Normalize response\n",
    "    if isinstance(response, list):\n",
    "        response = \"\".join(response)\n",
    "    elif hasattr(response, \"content\"):\n",
    "        response = response.content\n",
    "    elif isinstance(response, bytes):\n",
    "        response = response.decode(\"utf-8\")\n",
    "\n",
    "    response = response.replace(\"\\n\", \"\").strip()\n",
    "\n",
    "    return {**state, \"output\": response}\n",
    "\n",
    "def route_node(state: AgentState) -> str:\n",
    "    print(\"[Router] Deciding next node based on RAG availability...\")\n",
    "    return \"rag_generation\" if state[\"used_rag\"] else \"fallback_generation\"\n",
    "\n",
    "# Build LangGraph\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"retrieval\", retrieval_node)\n",
    "graph.add_node(\"rag_generation\", rag_generation_node)\n",
    "graph.add_node(\"fallback_generation\", fallback_generation_node)\n",
    "\n",
    "# Routing\n",
    "graph.add_conditional_edges(\"retrieval\", route_node, {\n",
    "    \"rag_generation\": \"rag_generation\",\n",
    "    \"fallback_generation\": \"fallback_generation\"\n",
    "})\n",
    "\n",
    "# Edges\n",
    "graph.add_edge(\"rag_generation\", END)\n",
    "graph.add_edge(\"fallback_generation\", END)\n",
    "\n",
    "# Set entry point\n",
    "graph.set_entry_point(\"retrieval\")\n",
    "\n",
    "# Compile graph\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b390d05b-75aa-406d-bbb4-beaa53649a93",
   "metadata": {},
   "source": [
    "### 6. Testing nodes and RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94e53f8-dada-40dd-a840-55bb35ef600d",
   "metadata": {},
   "source": [
    "The final operation of the agent. Now it prints the order of nodes, usage of RAG and the answer without special characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8557cefc-b789-4d83-a32b-64620533c630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node] retrieval_node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Router] Deciding next node based on RAG availability...\n",
      "[Node] rag_generation_node\n",
      "Answer: Use the following context to answer:In Greek mythology, Achilles ( ) or Achilleus () was a hero of the Trojan War, the greatest of all the Greek warriors, and is the central character of Homer's Iliad. He was the son of the Nereid Thetis and Peleus, king of Phthia.According to the Achilleid, written by Statius in the 1st century AD, and to non-surviving previous sources, when Achilles was born Thetis tried to make him immortal by dipping him in the river Styx; however, he was left vulnerable at the part of the body by which she held him: his left heel (see Achilles' heel, Achilles' tendon). It is not clear if this version of events was known earlier. InAchilles is the subject of the poem Achilleis (1799), a fragment by Johann Wolfgang von Goethe. In 1899, the Polish playwright, painter and poet Stanisaw Wyspiaski published a national drama, based on Polish history, named Achilles. In 1921, Edward Shanks published The Island of Youth and Other Poems, concerned among others with Achilles.Achilles is a major supporting character in David Gemmell's Troy series of books (20052007). Achilles is the main character in David Malouf's novel Ransom (2009). The ghost of Achilles appears in Rick Riordan's The Last Olympian (2009). He warns Percy Jackson about the Curse of Achilles and its side effects. Achilles is a main character in Terence Hawkins' 2009 novel The Rage of Achilles.\n",
      "Used RAG: True\n"
     ]
    }
   ],
   "source": [
    "result = app.invoke({\"input\": \"Who was Achilles?\"})\n",
    "print(\"Answer:\", result[\"output\"])\n",
    "print(\"Used RAG:\", result[\"used_rag\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e7a3dc-0b08-4399-898d-4e5e198fb813",
   "metadata": {},
   "source": [
    "Earlier version of the agent - this is the reason, why I had to remove non ASCII characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4b1d97b-fdcd-4744-bea0-db1d3833d312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node] retrieval_node\n",
      "[Router] Deciding next node based on RAG availability...\n",
      "[Node] rag_generation_node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Use the following context to answer:denote fives –five units, five tens, etc., essentially in a bi-quinary coded decimal system, related to the Roman numerals. The short grooves on the right may have been used for marking Roman \"ounces\" (i.e. fractions).earn 5 sacks (200 kg or 400 lb) of grain per month, while a foreman might earn 7 sacks (250 kg or 550 lb). Prices were fixed across the country and recorded in lists to facilitate trading; for example a shirt cost five copper deben, while a cow cost 140deben. Grain could be traded for other goods, according to the fixed price list. During the fifth centuryBC coined money was introduced into Egyptwas 5 per one million, which included children and adults.tracking and data acquisition network, added an additional $5.2 billion ($ adjusted).($))()()())())))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "Used RAG: True\n"
     ]
    }
   ],
   "source": [
    "result = app.invoke({\"input\": \"How much is 5+5?\"})\n",
    "print(\"Answer:\", result[\"output\"])\n",
    "print(\"Used RAG:\", result[\"used_rag\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
